/**
 * ç”Ÿæˆ Graph View æ‰€éœ€çš„é“¾æ¥æ•°æ®
 * æ‰«ææ‰€æœ‰ markdown æ–‡ä»¶ï¼Œæå– wikilinks å¹¶ç”ŸæˆèŠ‚ç‚¹å’Œè¾¹
 */

import fs from 'fs'
import path from 'path'
import { glob } from 'glob'
import matter from 'gray-matter'
import { fileURLToPath } from 'url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)
const rootDir = path.resolve(__dirname, '..')

// Wikilink æ­£åˆ™è¡¨è¾¾å¼: [[link]] æˆ– [[link|text]]
const WIKILINK_REGEX = /\[\[([^\]|]+)(?:\|[^\]]+)?\]\]/g

/**
 * å°† wikilink target è§£æä¸ºè·¯ç”±è·¯å¾„
 * ä¾‹å¦‚: "obsidian-features" -> "/example/obsidian-features"
 */
function resolveWikilinkPath(target, currentFilePath, allPaths) {
  // ç§»é™¤å¯èƒ½çš„ # é”šç‚¹
  const cleanTarget = target.split('#')[0].trim()

  if (!cleanTarget) return null

  // å¦‚æœå·²ç»æ˜¯ç»å¯¹è·¯å¾„å½¢å¼
  if (cleanTarget.startsWith('/')) {
    return cleanTarget
  }

  // å°è¯•åœ¨æ‰€æœ‰è·¯å¾„ä¸­æŸ¥æ‰¾åŒ¹é…
  // ç­–ç•¥1: å®Œå…¨åŒ¹é…æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
  const targetLower = cleanTarget.toLowerCase()

  for (const p of allPaths) {
    const basename = path.basename(p.filePath, '.md').toLowerCase()
    if (basename === targetLower) {
      return p.routePath
    }
  }

  // ç­–ç•¥2: å°è¯•ç›¸å¯¹äºå½“å‰æ–‡ä»¶ç›®å½•è§£æ
  const currentDir = path.dirname(currentFilePath)
  const possiblePath = path.join(currentDir, cleanTarget).replace(/\\/g, '/')

  for (const p of allPaths) {
    if (p.filePath.includes(possiblePath)) {
      return p.routePath
    }
  }

  return null
}

/**
 * ä»æ–‡ä»¶è·¯å¾„ç”Ÿæˆè·¯ç”±è·¯å¾„
 */
function filePathToRoutePath(filePath, baseDir) {
  let routePath = filePath
    .replace(baseDir, '')
    .replace(/\\/g, '/')
    .replace(/\.md$/, '')
    .replace(/\/index$/, '')

  if (!routePath.startsWith('/')) {
    routePath = '/' + routePath
  }

  return routePath
}

async function generateGraphData() {
  console.log('ğŸ“Š Generating graph data...')

  const docsDir = path.join(rootDir, 'docs')
  const pagesDir = path.join(rootDir, 'src/pages')

  // æŸ¥æ‰¾æ‰€æœ‰ markdown æ–‡ä»¶
  const docFiles = await glob('**/*.md', { cwd: docsDir })
  const pageFiles = await glob('**/*.md', { cwd: pagesDir })

  // æ„å»ºæ‰€æœ‰æ–‡ä»¶è·¯å¾„æ˜ å°„
  const allPaths = []

  for (const file of docFiles) {
    const filePath = path.join(docsDir, file)
    const routePath = filePathToRoutePath(file, '')
    allPaths.push({ filePath, routePath, baseDir: docsDir })
  }

  for (const file of pageFiles) {
    const filePath = path.join(pagesDir, file)
    const routePath = filePathToRoutePath(file, '')
    allPaths.push({ filePath, routePath, baseDir: pagesDir })
  }

  const nodes = []
  const links = []
  const nodeSet = new Set()

  // å¤„ç†æ¯ä¸ªæ–‡ä»¶
  for (const { filePath, routePath } of allPaths) {
    try {
      const content = fs.readFileSync(filePath, 'utf-8')
      const { data, content: markdownBody } = matter(content)

      const title = data.title || path.basename(filePath, '.md')

      // æ·»åŠ èŠ‚ç‚¹
      if (!nodeSet.has(routePath)) {
        nodeSet.add(routePath)
        // ä»è·¯å¾„æå–åˆ†ç±»ï¼ˆç¬¬ä¸€æ®µè·¯å¾„ï¼‰
        const pathParts = routePath.split('/').filter(Boolean)
        const category = pathParts[0] || 'root'

        nodes.push({
          id: routePath,
          title: title,
          path: routePath,
          category: category,
          tags: data.tags || []
        })
      }

      // æå– wikilinks
      let match
      while ((match = WIKILINK_REGEX.exec(markdownBody)) !== null) {
        const target = match[1].trim()
        const targetPath = resolveWikilinkPath(target, filePath, allPaths)

        if (targetPath && targetPath !== routePath) {
          // ç¡®ä¿ç›®æ ‡èŠ‚ç‚¹å­˜åœ¨
          if (!nodeSet.has(targetPath)) {
            // å°è¯•è·å–ç›®æ ‡æ–‡ä»¶çš„æ ‡é¢˜å’Œå…ƒæ•°æ®
            const targetInfo = allPaths.find((p) => p.routePath === targetPath)
            let targetTitle = path.basename(targetPath)
            let targetTags = []

            if (targetInfo) {
              try {
                const targetContent = fs.readFileSync(targetInfo.filePath, 'utf-8')
                const { data: targetData } = matter(targetContent)
                targetTitle = targetData.title || targetTitle
                targetTags = targetData.tags || []
              } catch (e) {
                // å¿½ç•¥è¯»å–é”™è¯¯
              }
            }

            // ä»è·¯å¾„æå–åˆ†ç±»
            const targetPathParts = targetPath.split('/').filter(Boolean)
            const targetCategory = targetPathParts[0] || 'root'

            nodeSet.add(targetPath)
            nodes.push({
              id: targetPath,
              title: targetTitle,
              path: targetPath,
              category: targetCategory,
              tags: targetTags
            })
          }

          // æ·»åŠ é“¾æ¥ï¼ˆé¿å…é‡å¤ï¼‰
          const linkKey = `${routePath}->${targetPath}`
          const existingLink = links.find((l) => l.source === routePath && l.target === targetPath)

          if (!existingLink) {
            links.push({
              source: routePath,
              target: targetPath
            })
          }
        }
      }
    } catch (error) {
      console.warn(`Failed to process ${filePath}:`, error.message)
    }
  }

  // è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„é“¾æ¥æ•°
  const linkCounts = {}
  for (const link of links) {
    linkCounts[link.source] = (linkCounts[link.source] || 0) + 1
    linkCounts[link.target] = (linkCounts[link.target] || 0) + 1
  }

  // æ·»åŠ é“¾æ¥æ•°åˆ°èŠ‚ç‚¹
  for (const node of nodes) {
    node.links = linkCounts[node.id] || 0
  }

  const graphData = { nodes, links }

  // å†™å…¥ public ç›®å½•
  const publicDir = path.join(rootDir, 'public')
  if (!fs.existsSync(publicDir)) {
    fs.mkdirSync(publicDir, { recursive: true })
  }

  const outputPath = path.join(publicDir, 'graph-data.json')
  fs.writeFileSync(outputPath, JSON.stringify(graphData, null, 2))

  console.log(`âœ… Graph data generated: ${nodes.length} nodes, ${links.length} links`)
  console.log(`   Output: ${outputPath}`)
}

generateGraphData().catch(console.error)
